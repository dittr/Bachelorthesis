% section
\section{Conclusion} \label{section::conclusion}
 This thesis showed different approaches for image-/video-prediction and how important the choice of the recurrent sub-module is.
 First the reader got an extensive introduction
 about all necessary topics, which were necessary to fully understand the following chapters. Afterwards, the thesis gave a comprehensive related work part, in 
 which five state-of-the-art image-/video-prediction algorithms are described, by showing the architecture and the results of the experiments of the synthetic 
 dataset. This five architectures showed, how different the approaches for image-/video-prediction are, but also how similar in form of
 having a similar recurrent module and some using a type of autoencoder architecture.
 \\\\
 Because the re-implementation
 of three baselines is a big part of this bachelor thesis, the implementation chapter described how the code is structured and how to use the code, so any
 user (with minimal knowledge of PyTorch / neural networks) is able to use and possibly adapt the code for validating the performed experiments or even perform
 own further experiments. Then the reader got the methodology in the experiment section~\ref{subsection::exp_setup}, to understand in which the way the 
 experiments are performed, so the reader will apprehend the key-aspects of the experiments.
 \\\\
 The experimental results were given in the experiments section.
 The experiments showed, how important the right choice of a recurrent module is and also how important hyperparameter optimization is in training neural networks.
 The first experiments were performed using static settings for all network implementations. Those experiments showed, that without using the \glqq best\grqq{} 
 hyperparameters for each network, the choice of a more advanced recurrent module is not necessary.
 \\\\ 
 After performing hyperparameter optimization and using given \glqq optimal\grqq{} values 
 from the implemented papers, even one example already showed that
 PredRNN should be the superior module and should be tested again in all implemented architectures.\\
 This showed the relevance of hyperparameter optimization in machine learning. If one thinks about a neural network consisting of different sub-modules as a
 football team, then the nerual network itself is the whole team and every player describes a specific sub-module. When one now has a very untrained football team
 and buys only one very good player, it is unlikely, that this player is able to fix the problems the whole team had before. It is likely, that the team will
 not perform better. This is exactly the analogy for the first performed experiments. The network itself was in bad shape, so even a likely superior
 sub-module was not able to let the network perform any better. After performing the hyperparameter optimization, the example showed how much better the
 whole network performed. To stick to the football analogy, this would mean, after optimizing the whole team, it is really related to a likely new and better 
 player to optimize the performance. This is actually seen very often in football, that the first approach is to strengthen the whole team, before adding superior
 players to peak the performance of the whole team. 
 \\\\
 Lastly, there is the discussion in which
 the reader gets an interpretation of the experimental results and how they affect image-/video-prediction neural networks.
 \\
 For future experiments, it would be awesome to see the hyperparameter optimization performed for all $18$ test cases and if PredRNN is able to outperform
 the standard ConvLSTM module in all of the tests.