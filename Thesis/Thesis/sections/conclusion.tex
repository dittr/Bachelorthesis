% section
\section{Conclusion} \label{section::conclusion}
 The thesis showed different approaches for image-/video-prediction and how important the choice of the recurrent sub-module is.
 First the reader got an extensive introduction
 about all necessary topics, which were necessary to fully understand the following chapters. Then the thesis gave a comprehensive related work part, in which
 five state-of-the-art image-/video-prediction algorithms are described, by showing the architecture and the results of the experiments of the synthetic dataset.
 This five architectures showed, how different the approaches for image-/video-prediction are, but also how similar in form of
 having a similar recurrent module and some using a type of autoencoder architecture.
 \\\\
 Because the re-implementation
 of the three baselines is a big part of this bachelor thesis, the implementation chapter described how the code is structured and how to use the code, so any
 user (with minimal knowledge of PyTorch / neural networks) is able to use and possibly adapt the code for validating the performed experiments or even perform
 own further experiments. Then the reader got the methodology, in which the way how the experiments are performed is described in-depth, so the reader will 
 understand the key-aspects of the experiments.
 \\\\
 The experimental results were given in the experiments section.
 The experiments showed, how important the right choice of a recurrent module is and also how important hyperparameter optimization is in training neural networks.
 The first experiments were performed using static settings for all network implementations. Those experiments showed, that without using the \glqq best\grqq 
 hyperparameters for each network, the choice of a more advanced recurrent module is not necessary.
 \\\\ 
 After performing hyperparameter optimization and using given \glqq optimal\grqq values 
 from the implemented papers, even one example already showed that
 PredRNN should be the superior module and should be tested again in all implemented architectures. 
 Lastly, there is the discussion in which
 the reader gets an interpretation of the experimental results and how they affect image-/video-prediction neural networks.
 \\\\
 For future experiments, it would be awesome to see the hyperparameter optimization performed for all $18$ test cases and if PredRNN is able to outperform
 the standard ConvLSTM module in all of the tests.