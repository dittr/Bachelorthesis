% framework (PyTorch / Tensorboard)

% 1. PyTorch
@incollection{Paszke2019,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {8024--8035},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}
% 2. Tensorboard
@misc{tensorflow2015,
title={ {TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
url={https://www.tensorflow.org/},
note={Software available from tensorflow.org},
author={
    Mart\'{\i}n~Abadi and
    Ashish~Agarwal and
    Paul~Barham and
    Eugene~Brevdo and
    Zhifeng~Chen and
    Craig~Citro and
    Greg~S.~Corrado and
    Andy~Davis and
    Jeffrey~Dean and
    Matthieu~Devin and
    Sanjay~Ghemawat and
    Ian~Goodfellow and
    Andrew~Harp and
    Geoffrey~Irving and
    Michael~Isard and
    Yangqing Jia and
    Rafal~Jozefowicz and
    Lukasz~Kaiser and
    Manjunath~Kudlur and
    Josh~Levenberg and
    Dandelion~Man\'{e} and
    Rajat~Monga and
    Sherry~Moore and
    Derek~Murray and
    Chris~Olah and
    Mike~Schuster and
    Jonathon~Shlens and
    Benoit~Steiner and
    Ilya~Sutskever and
    Kunal~Talwar and
    Paul~Tucker and
    Vincent~Vanhoucke and
    Vijay~Vasudevan and
    Fernanda~Vi\'{e}gas and
    Oriol~Vinyals and
    Pete~Warden and
    Martin~Wattenberg and
    Martin~Wicke and
    Yuan~Yu and
    Xiaoqiang~Zheng},
  year={2015},
}

% datasets

% 1. MovingMNIST dataset
@ARTICLE{LeCun1998,
  author={Y. {Lecun} and L. {Bottou} and Y. {Bengio} and P. {Haffner}},
  journal={Proceedings of the IEEE}, 
  title={Gradient-based learning applied to document recognition}, 
  year={1998},
  volume={86},
  number={11},
  pages={2278-2324}
}
% 2. Kitti dataset
@ARTICLE{Geiger2013,
  author = {Andreas Geiger and Philip Lenz and Christoph Stiller and Raquel Urtasun},
  title = {Vision meets Robotics: The KITTI Dataset},
  journal = {International Journal of Robotics Research (IJRR)},
  year = {2013}
}
% 3. KTH dataset
@inproceedings{Schüldt2004,
author = {Schüldt, Christian and Laptev, Ivan and Caputo, Barbara},
year = {2004},
month = {09},
pages = {32 - 36 Vol.3},
title = {Recognizing human actions: A local SVM approach},
volume = {3},
isbn = {0-7695-2128-2},
journal = {Proceedings - International Conference on Pattern Recognition},
doi = {10.1109/ICPR.2004.1334462}
}
% 4. Caltech Pedestrian
@article{Dollar2012,
  author = {Piotr Doll\'ar and Christian Wojek and Bernt Schiele and Pietro Perona},
  title = {Pedestrian Detection: An Evaluation of the State of the Art},
  journal = {PAMI},
  volume = {34},
  year = {2012},
}

% optimizer

% 1. Adam
@inproceedings{Kingma2015,
  author    = {Diederik P. Kingma and
               Jimmy Ba},
  title     = {Adam: {A} Method for Stochastic Optimization},
  booktitle = {3rd International Conference on Learning Representations, {ICLR} 2015,
               San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings},
  year      = {2015},
  url       = {http://arxiv.org/abs/1412.6980}
}
% 2. RmsProp (not published, use secondary)
@article{Ruder2016,
  author    = {Sebastian Ruder},
  title     = {An overview of gradient descent optimization algorithms},
  journal   = {CoRR},
  volume    = {abs/1609.04747},
  year      = {2016},
  url       = {http://arxiv.org/abs/1609.04747},
  archivePrefix = {arXiv},
  eprint    = {1609.04747}
}

% Error functions for images

% 1. Image Restoration
@ARTICLE{Zhao2017, 
    author={H. {Zhao} and O. {Gallo} and I. {Frosio} and J. {Kautz}},  journal={IEEE Transactions on Computational Imaging},   title={Loss Functions for Image Restoration With Neural Networks},   year={2017},  volume={3},  number={1},  pages={47-57},}

% LSTM / ConvLSTM

% 1. LSTM
@article{Hochreiter1997,
author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
year = {1997},
month = {12},
pages = {1735-80},
title = {Long Short-term Memory},
volume = {9},
journal = {Neural computation},
doi = {10.1162/neco.1997.9.8.1735}
}
% 2. ConvLSTM
@incollection{Shi2015,
title = {Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting},
author = {SHI, Xingjian and Chen, Zhourong and Wang, Hao and Yeung, Dit-Yan and Wong, Wai-kin and WOO, Wang-chun},
booktitle = {Advances in Neural Information Processing Systems 28},
editor = {C. Cortes and N. D. Lawrence and D. D. Lee and M. Sugiyama and R. Garnett},
pages = {802--810},
year = {2015},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/5955-convolutional-lstm-network-a-machine-learning-approach-for-precipitation-nowcasting.pdf}
}

% 3. LSTM with peephole
@INPROCEEDINGS{Gers2000,  author={F. A. {Gers} and J. {Schmidhuber}},  booktitle={Proceedings of the IEEE-INNS-ENNS International Joint Conference on Neural Networks. IJCNN 2000. Neural Computing: New Challenges and Perspectives for the New Millennium},   title={Recurrent nets that time and count},   year={2000},  volume={3},  number={},  pages={189-194 vol.3},}

% 4. LSTM used in Srivastava et. al.
@article{Graves2013,
  author    = {Alex Graves},
  title     = {Generating Sequences With Recurrent Neural Networks},
  journal   = {CoRR},
  volume    = {abs/1308.0850},
  year      = {2013},
  url       = {http://arxiv.org/abs/1308.0850},
  archivePrefix = {arXiv},
  eprint    = {1308.0850},
  timestamp = {Mon, 13 Aug 2018 16:47:21 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/Graves13.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

% Baselines / Paper

% 1. PredNet
@article{Lotter2016,
  author    = {William Lotter and
               Gabriel Kreiman and
               David D. Cox},
  title     = {Deep Predictive Coding Networks for Video Prediction and Unsupervised
               Learning},
  journal   = {CoRR},
  volume    = {abs/1605.08104},
  year      = {2016},
  url       = {http://arxiv.org/abs/1605.08104},
  archivePrefix = {arXiv},
  eprint    = {1605.08104}
}
% 2. Spatio temporal Video Autoencoder with differentiable Memory
@article{Patraucean2015,
  author    = {Viorica Patraucean and
               Ankur Handa and
               Roberto Cipolla},
  title     = {Spatio-temporal video autoencoder with differentiable memory},
  journal   = {CoRR},
  volume    = {abs/1511.06309},
  year      = {2015},
  url       = {http://arxiv.org/abs/1511.06309},
  archivePrefix = {arXiv},
  eprint    = {1511.06309}
}
% 3. PredRNN
@inproceedings{Wang2017,
  title={PredRNN: Recurrent Neural Networks for Predictive Learning using Spatiotemporal LSTMs},
  author={Yunbo Wang and Mingsheng Long and Jianmin Wang and Zhifeng Gao and Philip S. Yu},
  booktitle={NIPS},
  year={2017}
}
% 4. PredRNN++
@article{Wang2018,
  author    = {Yunbo Wang and
               Zhifeng Gao and
               Mingsheng Long and
               Jianmin Wang and
               Philip S. Yu},
  title     = {PredRNN++: Towards {A} Resolution of the Deep-in-Time Dilemma in Spatiotemporal
               Predictive Learning},
  journal   = {CoRR},
  volume    = {abs/1804.06300},
  year      = {2018},
  url       = {http://arxiv.org/abs/1804.06300},
  archivePrefix = {arXiv},
  eprint    = {1804.06300},
  timestamp = {Mon, 13 Aug 2018 16:49:13 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1804-06300.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
% 5. LSTM Autoencoder
@article{Srivastava2015,
  author    = {Nitish Srivastava and
               Elman Mansimov and
               Ruslan Salakhutdinov},
  title     = {Unsupervised Learning of Video Representations using LSTMs},
  journal   = {CoRR},
  volume    = {abs/1502.04681},
  year      = {2015},
  url       = {http://arxiv.org/abs/1502.04681},
  archivePrefix = {arXiv},
  eprint    = {1502.04681},
  timestamp = {Mon, 13 Aug 2018 16:47:05 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/SrivastavaMS15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

% Predictive Coding

% 1. Cortical Responses
@article{Friston2005,
author = {Friston, Karl},
year = {2005},
month = {05},
pages = {815-36},
title = {A Theory of Cortical Responses},
volume = {360},
journal = {Philosophical transactions of the Royal Society of London. Series B, Biological sciences},
doi = {10.1098/rstb.2005.1622}
}
% 2. Visual Context
@Article{Rao1999,
author={Rao, Rajesh P. N.
and Ballard, Dana H.},
title={Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects},
journal={Nature Neuroscience},
year={1999},
month={Jan},
day={01},
volume={2},
number={1},
pages={79-87},
issn={1546-1726},
doi={10.1038/4580},
url={https://doi.org/10.1038/4580}
}

% PredNet critics

% 1. Critical Review
@article{Rane2019,
  author    = {Roshan Rane and
               Vageesh Saxena and
               Edit Sz{\"{u}}gyi},
  title     = {Video Action Classification Using PredNet},
  journal   = {CoRR},
  volume    = {abs/1906.11902},
  year      = {2019},
  url       = {http://arxiv.org/abs/1906.11902},
  archivePrefix = {arXiv},
  eprint    = {1906.11902}
}
% 2. rcg-LSTM
@article{Elsayed2018,
  author    = {Nelly Elsayed and
               Anthony S. Maida and
               Magdy A. Bayoumi},
  title     = {Reduced-Gate Convolutional {LSTM} Using Predictive Coding for Spatiotemporal
               Prediction},
  journal   = {CoRR},
  volume    = {abs/1810.07251},
  year      = {2018},
  url       = {http://arxiv.org/abs/1810.07251},
  archivePrefix = {arXiv},
  eprint    = {1810.07251}
}


% Misc papers

% 1. Sequence-to-Sequence learning
@article{Sutskever2014,
  author    = {Ilya Sutskever and
               Oriol Vinyals and
               Quoc V. Le},
  title     = {Sequence to Sequence Learning with Neural Networks},
  journal   = {CoRR},
  volume    = {abs/1409.3215},
  year      = {2014},
  url       = {http://arxiv.org/abs/1409.3215},
  archivePrefix = {arXiv},
  eprint    = {1409.3215},
  timestamp = {Mon, 13 Aug 2018 16:48:06 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/SutskeverVL14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

2. Spatial Transformer Networks
@article{Jadeberg2015,
  author    = {Max Jaderberg and
               Karen Simonyan and
               Andrew Zisserman and
               Koray Kavukcuoglu},
  title     = {Spatial Transformer Networks},
  journal   = {CoRR},
  volume    = {abs/1506.02025},
  year      = {2015},
  url       = {http://arxiv.org/abs/1506.02025},
  archivePrefix = {arXiv},
  eprint    = {1506.02025},
  timestamp = {Mon, 13 Aug 2018 16:49:02 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/JaderbergSZK15.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

% 3. Perceptron
@article{Rosenblatt1957,
    author  = {Frank Rosenblatt},
    title   = {The Perceptron — A Perceiving and Recognizing Automaton},
    journal = {Tech. Rep. 85-460-1},
    year    = {1957}
}

% Books

% 1. Deep Learning
@book{Goodfellow2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}


% Images

% 1. LSTM chain
@misc{Olah2015,
  title = {Understanding LSTM Networks},
  howpublished = {\url{https://colah.github.io/posts/2015-08-Understanding-LSTMs/}},
  note = {Accessed: 2020-07-13}
}

@misc{wiki2019,
  author = {Michela Massi},
  title = "Autoencoder schema --- {W}ikipedia{,} The Free Encyclopedia",
  year = "2019",
  url = "https://en.wikipedia.org/wiki/Autoencoder#/media/File:Autoencoder_schema.png",
  note = "[Online; accessed 21-Juli-2020]"
}

% Backpropagation

% 1. BPTT
@article{Werbos1990,
author = {Werbos, Paul},
year = {1990},
month = {11},
pages = {1550 - 1560},
title = {Backpropagation through time: what it does and how to do it},
volume = {78},
journal = {Proceedings of the IEEE},
doi = {10.1109/5.58337}
}

@Article{Rumelhart1986,
author={Rumelhart, David E.
and Hinton, Geoffrey E.
and Williams, Ronald J.},
title={Learning representations by back-propagating errors},
journal={Nature},
year={1986},
month={Oct},
day={01},
volume={323},
number={6088},
pages={533-536},
abstract={We describe a new learning procedure, back-propagation, for networks of neurone-like units. The procedure repeatedly adjusts the weights of the connections in the network so as to minimize a measure of the difference between the actual output vector of the net and the desired output vector. As a result of the weight adjustments, internal `hidden' units which are not part of the input or output come to represent important features of the task domain, and the regularities in the task are captured by the interactions of these units. The ability to create useful new features distinguishes back-propagation from earlier, simpler methods such as the perceptron-convergence procedure1.},
issn={1476-4687},
doi={10.1038/323533a0},
url={https://doi.org/10.1038/323533a0}
}
